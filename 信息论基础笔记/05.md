# 第六章 信道容量



## 一、信道

- 信息传输的通道
- 信息论关注其传输规律，高于其物理特性
- 确定信道的数学模型



### 1.1 二元对称信道(BSC)

- 输入符号集$X=\{0,1\}$
- 以一定概率翻转
- 如何传输字符$\{A,B\}$

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114212657889.png" alt="image-20191114212657889" style="zoom:80%;" />



### 1.2 离散信道

- 输入字符集$X$
- 输出字符集$Y$
- 转移矩阵$p(y|X)：$发出字符X的情况下收到输出字符y的概率

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114212839659.png" alt="image-20191114212839659" style="zoom:80%;" />



### 1.3 离散无记忆信道(DMC)

- 离散输入并有时间下标
- 存在独立噪声
- 如果仅与当前输入有关，与之前时刻的输入/输出条件独立，则为无记忆的(Memoryless)

$$
\begin{align}
无记忆：  &\\
p(Y|X)&=p(y_1,y_2,\dots,y_n|x_1,x_2,\dots,x_n)\\
&=p(y_1|x_1)p(y_2|x_2)\dots p(y_n|x_n)\\
&=\prod\limits_{i=1}^{n}p(y_i|x_i)
\end{align}
$$



## 二、信道容量

- 信道传输信息的能力
- 即每个符号/每次使用信道，可以传输的信息量
- 离散无记忆的信息信道容量：

$$
C=\max\limits_{p(x)} I(X;Y)
$$

- 即优化输入分布，使得输入输出的互信息达到最大



### 2.1 关于互信息$I(X;Y)$

#### 统计方面的意义

- Y的不确定度减去已知X的情况下Y的不确定度
- 已知X之后，Y的不确定降低的部分
- X与Y的相关度或者依赖度



#### 信道中的意义

- 接收到符号Y后平均每个符号获得的关于X的信息量
- 每次使用信道/每次传递一个符号，经过信道的信息量



#### 流程解释

![image-20191114214115848](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114214115848.png)

![image-20191114214206275](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114214206275.png)



### 2.2 一些简单信道容量



#### 无噪声信道

- 单次使用信道传输1bit
- 没有噪声，没有损失

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114214356444.png" alt="image-20191114214356444" style="zoom:80%;" />
$$
\begin{align}
C&=\max\limits_{p(x)} I(X;Y)\\
&=\max\limits_{p(x)} (H(X)-H(X|Y))\\
&=\max\limits_{p(x)} (H(X)-0)\\
&=1
\end{align}
$$



#### 无重叠的噪声信道

- 每次使用传输1bit
- 没有损失，但有噪声($H(Y|X)>0$)

![image-20191114214545170](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114214545170.png)
$$
\begin{align}
C&=\max\limits_{p(x)} I(X;Y)\\
&=\max\limits_{p(x)} (H(X)-H(X|Y))\\
&=\max\limits_{p(x)} (H(X)-0)\\
&=1
\end{align}
$$



#### 有噪声的打字机信道

- 可以无误差的传输其中的13个字母

$$
\begin{align}
C&=\max\limits_{p(x)} I(X;Y)\\
&=\max\limits_{p(x)} (H(Y)-H(Y|X))\\
&=log|y|-1\\
&=log26-1\\
&=log13\\\\
H(Y|X)&=\sum\limits_{x}p(x)H(Y|X)\\
&=\sum\limits_xp(x)H(\frac12,\frac12)\\
&=\sum\limits_xp(x)\\
&=1

\end{align}
$$



### 2.3 二元对称信道



#### 信道容量

- BSC-另一种表述方式
- 信道可以传输

$$
C=1-h_b(\varepsilon)
$$

- 当$\varepsilon=0.5时，X与Y独立$

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114224004411.png" alt="image-20191114224004411" style="zoom:80%;" />

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114224108022.png" alt="image-20191114224108022" style="zoom:80%;" />



### 2.4 二元擦除信道

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191114224215160.png" alt="image-20191114224215160" style="zoom:80%;" />

- 输出符号e擦除
- 多用于描述网络报文丢失模型

#### 信道容量

$$
\begin{align}
C&=\max\limits_{p(x)} I(X;Y)\\
&=\max\limits_{p(x)} (H(Y)-H(Y|X))\\
&=\max\limits_{p(x)}(H(Y)-h_b(\gamma))
\end{align}
$$

**H(Y|E)**

- 定义$p(0)=a$，事件E为：

$$
E=
\begin{cases}
0,Y\ne e&\\
1,Y=e\\
\end{cases}
\\\\
\begin{align}
p(E=0)&=a(1-\gamma)+(1-a)(1-\gamma)\\
&=1-\gamma\\
p(E=1)&=\gamma\\
\end{align}
$$

$$
\begin{align}
&H(E)=h_b(\gamma)\\\\
H(Y|E)&=p(E=0)H(Y|E=0)\\
&=(1-\gamma)\sum\limits_yp(y|E=0)log\ p(y|E=0)\\
&=(1-\gamma)h_b(a)
\end{align}
$$



**求信道容量C**
$$
\begin{align}
H(Y)&=H(Y,E)\\
&=H(E)+H(Y|E)\\\\
C&=\max\limits_{p(x)} H(Y)-h_b(\gamma)\\
&=\max\limits_{p(x)}h_b(\gamma)+(1-\gamma)h_b(a)-h_b(\gamma)\\
&=\max\limits_{p(x)}(1-\gamma)h_b(a)\\
&=1-\gamma
\end{align}
$$



## 三、 对称信道



### 1、转移矩阵



#### 对称

- 各行之和为1

- 各行各列互为重新排列


<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191126001257216.png" alt="image-20191126001257216" style="zoom:50%;" />



#### 弱对称

- 各行重新排列，各列之和相等


- TODO



####  弱对称信道容量

$$
C=log|Y|-H(转移矩阵的行)
$$

当输入字母表上的分布为均匀时达到该容量



## 四、信道容量的性质



### 4.1 基本性质

- 有界

  $0\le C\le log|X|$

  $0\le C\le log|Y|$

- 关于$p(x)$的连续凹函数，在凸集上有最大值

- 没有通用闭式解，但可以数值求解



### 4.2 信道容量的数值算法



**1、记X与Y的互信息为关于$p(x_i),p(x_i|y_i)$的函数**
$$
\begin{align}
I(X;Y)&=H(X)-H(X|Y)\\
&=-\sum\limits_ip(x_i)ln\ p(x_i)-\sum\limits_i\sum\limits_jp(x_i)p(y_j|x_i)ln\ p(x_i|y_j)\\
&=I[p(x_i),p(x_i|y_j)]
\end{align}
$$

**2、轮流固定$p(x_i),p(x_i|y_j)$，并以朗格拉日乘子求各自最优解**
$$
\begin{align}
p(x_i|y_j)&=\frac{p(x_i)p(y_j|x_i)}{\sum
\limits_ip(x_i)p(y_j|x_i)}\\\\

p(x_i)&=\frac{exp[\sum\limits_jp(y_j|x_i)ln\ p(x_i|y_j)]}{\sum\limits_iexp[\sum\limits_jp(y_j|x_i)ln\ p(x_i|y_j)]}
\end{align}
$$


**3、算法流程**

1. 初始化信源分布$P^{(0)=(p_1,p_2,\dots,p_n)}$
2. $p(x_i|y_j)^{(k)}=\varphi_{ji}^{(k)}=\frac{p_{ij}p_i^{(k)}}{\sum\limits_ip_{ij}p_i^{k}}$
3. $p_i^{(k+1)}=\frac{exp[\sum\limits_jp_{ij}ln\ \varphi_{ji}^{(k)}]}{\sum\limits_iexp[\sum\limits_jp_{ij}ln\ \varphi_{ji}^{(k)}]}$
4. $C^{(k+1)}=ln[\sum\limits_iexp[\sum\limits_jp_{ij\ ln \varphi_{ji}^{(k)}}]]$



## 五、信道编码定理预览

- 对于输入的每个(典型的)n长序列，会有大约$2^{nH(Y|X)}$个可能的$Y$序列与之对应
- 所有可能的(典型的)$Y$序列总数约为$2^{nH(Y)}$
- 不相交集的总数小于等于$2^{nH(Y)-nH(Y|X)}=2^{nI(X;Y)}$



### 5.1 一些定义

- 离散无记忆信道（码元层面）
  - 用$(X,p(y|x),Y)$表示
  - $X与Y$分别是信道的输入与输出
  - 概率密度函数满足$\sum\limits_yp(y|x)=1$

- DMC的$n$次扩展（码字层面）

  - 用$(X^n,p(y^n|x^n),Y)$表示
  - $p(y_k|x_k,y^{k-1})=p(y_k|x_k),k=1,2,\dots,n$
  - $p(y^n|x^n)=\prod\limits_{i=1}^np(y_i|x_i)$

- $(M,n)$码

  - 下标集$\{1,2,\dots,M\}$

  - 编码函数$X^n:\{1,2,\dots,M\}\to x^n$，生成码字$x^n(1),x^n(2),\dots,x^n(M)$，所有的码字集合称为码薄

  - 译码函数

    $g:Y^n\to\{1,2,\dots,M\}$

- 条件误差概率$\lambda_i$

  $\lambda_i=Pr(g(Y^n)\ne i|X^n=x^n(i))=\sum\limits_{y^n}p(y^n|x^n(i))I(g(y^n)\ne i)$

- 最大误差概率$\lambda^{(n)}$

  $\lambda^{(n)}=\max\limits_{i\in \{1,2,\dots,M\}}\ \lambda_i$

- 平均误差概率$P_e^{(n)}$

  $P_e^{(n)}=\frac{1}{M}\sum\limits_{i=1}^M\lambda_i$

- 码率$R$

  $R=\frac{log\ M}{n}$

- 可达码率

  如果存在一个$([2^{nR}],n)$码序列，满足当$n\to\infty$时，最大误差概率$\lambda^{(n)}\to0$，则称码率$R$是可达的

- $DMC$信道容量

  信道的容量定义为所有可达码率的上确界

  

### 5.2 联合典型序列

$X$序列典型，$Y$序列典型，同时$XY$序列典型

#### 定义

服从分布$p(x,y)$的联合典型序列$\{\{x^n,y^n\}\}$所构成的集合$A_\varepsilon^{(n)}$是指其经验熵与真实熵$\varepsilon$接近的n长序列构成的集合



#### 联合AEP

设$(X^n,Y^n)$服从$p(x^n,y^n)=\prod\limits_{i=1}^np(x_i,y_i)$独立同分布的$n$长序列，那么：

- 当$n\to\infty$时，$Pr((X^n,Y^n)\in A_{\varepsilon}^{(n)})\to1$

- $(1-\varepsilon)2^{n(H(X,Y)-\varepsilon)}\le |A_\varepsilon^{(n)}|\le 2^{n(H(X,Y)+\varepsilon)}$

- 如果$P(\widetilde{X}^n,\widetilde{Y}^n)\sim p(x^n)p(y^n)$，即$\widetilde{X}^n$与$\widetilde{Y}^n$是独立的且与$p(x^n,y^n)$有相同的边际分布，那么：

  $Pr{((\widetilde{X}^n,\widetilde{Y}^n)\in A_\varepsilon^{(n)})\le 2^{-n(I(X;Y)-3\varepsilon)}}$

  而且，对于充分大的$n$，

  $Pr((\widetilde{X}^n,\widetilde{Y}^n)\in A_\varepsilon^{(n)})\ge (1-\varepsilon)2^{-n(I(X;Y)+3\varepsilon)}$

  

![image-20191127002445636](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191127002445636.png)



## 六、信道编码定理



### 6.1 随机编码

- 对于分布$p(x)$
- 完全随机生成$(M,N)$码

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191127002624418.png" alt="image-20191127002624418" style="zoom:50%;" />
$$
Pr\{C\}=\prod\limits_{w=1}^{2^nR}\prod\limits_{i=1}^np(x_i(w))
$$



### 6.2 信道编码定理

- 对于离散无记忆信道，小于信道容量$C$的所有码率都是可达的。
- 具体的说：
  1. 对于任意码率$R<C$，存在一个$(2^{nR},n)$码序列，它的最大误差概率为$\lambda^{(n)}\to0$
  2. 任何满足$\lambda^{(n)}\to0$的$(2^{nR},n)$码序列必有$R\le C$



### 6.3 零误差码

- 一个零误差概率的$(2^{nR},n)$ 码，指译码器输出的$g(Y^n)$以概率1等于输入的下标，$H(W|Y^n)=0$

- 对于任何零误差$(2^{nR},n)$码：
  $$
  R\le C
  $$



**证明**
$$
\begin{align}
假定&W服从均匀分布\{1,2,\dots,2^{nR}\}\\
nR&=H(W)=H(W|Y^n)+I(W；Y^n)\\
&=0+I(W；Y^n)\\
&\le I(X^n;Y^n)\ 由于马尔可夫链：W\to X^n(W)\to Y^n\\
&\le \sum\limits_{i=1}^n I(X_i;Y_i)（离散无记忆信道假设）\\
&\le nC  （信道容量定理）\\
&所以：\\
&R\le C
\end{align}
$$


### 6.4 费诺不等式与编码定理的逆定理



#### 费诺不等式

设离散无记忆信道的码薄为$C$，且输入消息$W$服从$2^{nR}$上的均匀分布，则有：
$$
H(W|\hat{W})\le1+P_e^{(n)}nR
$$
其中：

- $P_e^{(n)}=Pr\{W\ne\hat W\}$
- 相应的马尔科夫链：$W\to X^n\to Y^n \to\hat W$



#### 引理

设$Y^n$为$X^n$经过容量为$C$离散无记忆信道传输所得的输出信号，则：
$$
I(X^n;Y^n)\le nc \ \ \ \forall p(x^n)
$$
**证明**
$$
\begin{align}
I(X^n;Y^n)&=H(Y^n)-H(Y^n|X^n)\\
&=H(Y^n)-\sum\limits_{i=1}^nH(Y_i|Y_1,Y_2,\dots,Y_{i-1},X^n)\\
&=H(Y^n)-\sum\limits_{i=1}^nH(Y_i|X_i)（一簇随机变量的熵小于各自熵的和）\\
&\le \sum\limits_{i=1}^nH(Y_i)-\sum\limits_{i=1}^nH(Y_i|X_i)\\
&=\sum\limits_{i=1}^nI(X_i;Y_i)\\
&\le nC（信道容量定义）
\end{align}
$$


#### 信道编码的逆定理

对于任何满足$\lambda^{(n)}\to0$的$(2^{nR},n)$码序列，必定有：
$$
R\le C
$$

**逆定理中的等式**
$$
\begin{align}
P_e=&0时：\\
nR&=H(W)\\
&=H(W|\hat W)+I(W;\hat W)\\
&=I(W;\hat W)\\
&\le I(X^n(W);Y^n)(数据处理不等式)（a）\\
&=H(Y^n)-(Y^n|X^n)\\
&=H(Y^n)-\sum\limits_{i=1}^nH(Y_i|X_i)\\
&\le\sum\limits_{i=1}^nH(Y_i)-\sum\limits_{i=1}^nH(Y_i|X_i)（b）\\
&=\sum\limits_{i=1}^nI(X_i;Y_i)\\
&\le nC （c）
\end{align}
$$

- 只有当$I(Y^n;X^n(W)|W)=0且I(X^n;Y^n|\hat W)=0$时，$a$处的数据不等式等号成立
- 只有当$Y_i$相互独立时，$b$处的等号才会成立
- 只有当$X_i$的分布为$p^*(x)$时，即达到信道容量$X$上的分布时，$c$处等号成立



## 七、反馈容量



### 7.1 反馈码

$(2^{nR},n)$反馈码由2以下部分组成：

1. 映射序列：$x_i(W,Y^{i-1})$

2. 译码函数序列：$g:Y^n=\{1,2,3,\dots,2^{nR}\}$

3. $x_i$是仅与当前消息$W\in 2^{nR}$和先前接收到的值$Y_1,Y_2,\dots,Y_{i-1}$的函数

4. 当$W$服从$\{1,2\dots,2^{nR}\}$上的均匀分布时，有：
   $$
   P_e^{(n)}=Pr\{g(Y^n)\ne W\}
   $$
   

### 7.2 反馈容量

离散无记忆信道的反馈容量$C_{FB}$定义为反馈码可以达到的所有码率的上确界
$$
C_{FB}=C=\max\limits_{p(x)}I(X;Y)
$$



## 八、信源信道分离定理



### 8.1 信源信道编码定理

- 如果$V^n=V_1,V_2,\cdots,V_n$，为有限字母表上满足**AEP**和$H(V)<C$的随机过程，则存在一个信源信道编码使得误差概率$Pr(\hat{V^n}\ne V^n)\to0$
- 反之，对任意平稳随机过程，如果$H(V)>C$，那么误差概率远离0，从而不可能以任意低的概率通过信道发送这个过程



