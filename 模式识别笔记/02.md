# 第二章 聚类分析



## 一、概念



### 1、聚类分析



#### 定义

根据模式样本之间的**相似性**对模式样本进行分类



#### 前提条件

样本所属类别未知



#### 聚类分析的目标

- 相似样本归为一类
- 不相似样本归为不同类



#### 聚类分析的关键问题

- 特征选择：略去多余的特征，选择合适的特征。
- 特征量化：连续量的量化、数量级标准化、特征权重、归一化
- 距离计算



### 2、相似性

#### 定义

- 每个样本由多个特征组成$X=[x_1,x_2,…,x_n]^T$
- $X$可以看成是n维空间的一个点
- 点之间的距离代表着样本的相似性



## 二、常用距离



### 1、欧氏距离

用于计算两个样本之间的距离，标量



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570775591122.png" alt="1570775591122" style="zoom:80%;" />



#### 要求

- 各维度上是相同的物理量
- 各维度上的物理量单位相同



#### 归一化公式

$X \  =\  \frac{X-X_{min}}{X_{max}-X_{min}}$



#### 优点

多个维度为同一个物理量且单位相同时，效果很好



#### 缺点

- 多个维度为不同物理量时，需要归一化
- 多个维度为不同单位时，需要标准化



### 2、马氏距离

用于计算样本偏离总体的程度，样本与总体均值的距离



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570777859414.png" alt="1570777859414" style="zoom:80%;" />

![1570777888155](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570777888155.png)

#### 要求

- 各维度上可以是不同的物理量
- 各维度上物理量的单位可以不同



#### 优点

- 可以消除量纲的影响
- 可以排除多个维度特征之间的关联



#### 缺点

- 要求总体样本数量大于每个样本的维数，否则协方差矩阵不存在逆矩阵



### 3、明式距离

计算任意两个样本的距离



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570780746319.png" alt="1570780746319" style="zoom:80%;" />



#### 含义

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570780890701.png" alt="1570780890701" style="zoom:80%;" />





#### 要求

- 各维度上是相同的物理量
- 各维度上的物理量单位相同



#### 优点

- 多个维度为同一个物理量且单位相同时，效果很好



#### 缺点

- 多个维度为不同物理量时，需要归一化
- 多个维度为不同单位时，需要标准化



### 4、汉明距离

用于计算任意两二值样本的距离



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570781608262.png" alt="1570781608262" style="zoom:80%;" />



#### 要求

- 各维度上是二值数据$[1,-1]$



#### 优点

- 能很好的反应两个二值样本的相似程度
- 与单位无关
- 与物理量无关



#### 缺点

- 维度数据不是二值时，需要二值化
- 维度数据不是1、-1时，需要码型转换



### 5、角度相似性函数

用于计算任意两个样本的夹角



#### 算法

![1570782232038](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570782232038.png)



#### 要求

- 各维度上是相同的物理量
- 各维度上的物理量单位相同



#### 优点

- 多个维度为同一个物理量且单位相同时，效果很好
- 旋转不变性
- 二值情况下与汉明距离相似、也是点积



#### 缺点

- 多个维度是不同物理量时，需要归一化
- 多个维度为不同的单位时，需要标准化



### 6、其他距离

- 卡方距离
- DTW距离
- 皮尔森相关系数



## 三、聚类准则



### 1、定义

根据相似性测度确定的，衡量模式之间是否相似的标准。



### 2、目标

样本间距离小到什么程度时，可归为一类？聚类准则确定



### 3、确定方法

- 阈值准则：根据规定的距离阈值进行分类
- 函数准则：利用聚类准则函数进行分类



### 4、聚类准则函数

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570861158403.png" alt="1570861158403" style="zoom:80%;" />



#### 误差平方和函数

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570861651423.png" alt="1570861651423" style="zoom:80%;" />

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570861667842.png" alt="1570861667842" style="zoom:80%;" />



## 四、基于阈值准则的聚类算法



### 1、近邻聚类法

将样本按照距离阈值T分类到若干模式类中



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570862464832.png" alt="1570862464832" style="zoom:80%;" />



#### 优点

计算简单、快速



#### 缺点

- 依赖于阈值T的大小
- 依赖于第一个聚类中心的位置选择
- 依赖于待分类样本的排列顺序
- 依赖于样本分布的几何性质



### 2、最大最小距离算法

将样本按照距离阈值T分类到若干模式类中



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570864409116.png" alt="1570864409116" style="zoom:80%;" />

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570864435049.png" alt="1570864435049" style="zoom: 75%;" />



#### 优点

- 计算简单、快捷
- 不依赖于特定分类模式样本的排列顺序



#### 缺点

- 依赖于阈值T的大小
- 依赖于第一个聚类中心位置的选择
- 依赖于样本分布的几何性质



### 3、层次聚类法

按照距离准则逐步合并，减少类别数



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570866886974.png" alt="1570866886974" style="zoom:80%;" />

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570866904897.png" alt="1570866904897" style="zoom:80%;" />



#### 类间计距离计算



**最短距离法**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570867275638.png" alt="1570867275638" style="zoom:80%;" />

- 计算简单、快速
- 易受个别异常点影响



**最长距离法**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570867390501.png" alt="1570867390501" style="zoom:80%;" />

- 计算简单、快速
- 易受个别异常点的影响



**中间距离法**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570867565232.png" alt="1570867565232" style="zoom:80%;" />

- 可降低个别异常点的影响
- 计算复杂



**重心法**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570867694689.png" alt="1570867694689" style="zoom:80%;" />

- 可降低少数异常点的影响
- 计算复杂



**类平均距离法**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1570867777751.png" alt="1570867777751" style="zoom:80%;" />



## 五、基于函数准则的聚类算法



### 1、动态聚类法



#### 基本思路

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571379162409.png" alt="1571379162409" style="zoom:80%;" />

#### 主要算法

- k-均值算法
- 迭代自组织的数据分析算法（ISODATA）



### 2、K—均值算法



#### 条件及其约定

- 设待分类的模式特征矢量集为$\{x_1,x_2...,x_N\};$
- 类的数目K是事先取定的



#### 基本思想

- 首先任取K个聚类中心，按照最小距离原则将各模式分配到K类中的某一类
- 动态调整聚类中心和各模式的类别，最终使准则函数取极小值



#### 准则函数

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571379331886.png" alt="1571379331886" style="zoom:80%;" />

#### 聚类准则

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571379508428.png" alt="1571379508428" style="zoom:80%;" />



#### 算法

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571380040268.png" alt="1571380040268" style="zoom:80%;" />



#### 优点

- 算法简单高效



#### 缺点

- 受初始聚类中心位置、聚类中心个数、模式样本几何性质、样本顺序的影响



#### 解决办法

- 试探不同的K值
- 选择不同的初始聚类中心



### 3、*ISODATA算法



#### 算法改进

- 可以动态改变类别的数目
- 合并
  - 类内样本个数太少
  - 两聚类中心之间距离太小
- 分裂
  - 某一类的类内方差过大



#### 基本思路

- 初始化：选择初始控制参数和聚类中心
- 分类：按照近邻规则进行分类
- 分裂与合并：根据参数分裂与合并，并获得新的聚类中心
- 结果评估：评估结果是否符合要求



#### 算法流程图

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571384078843.png" alt="1571384078843" style="zoom:80%;" />



#### 算法步骤

**第一步**

设置控制参数，聚类数和初始聚类中心

| 参数             | 描述                                                      |
| ---------------- | --------------------------------------------------------- |
| K                | 希望的聚类中心数目                                        |
| $\theta_N$       | 每个聚类中最少的样本数，用于控制合并                      |
| $\theta_C$       | 两聚类中心间的最短距离，用于控制合并                      |
| $\theta_S$       | 标准差阈值。所有分量中的最大值应小于$\theta_S$ ，否则分裂 |
| $L$              | 每次迭代允许合并的最大聚类对数                            |
| $N_c$            | 初始聚类数                                                |
| $z_i,i=1,2..N_c$ | 预设的初始聚类中心                                        |

**第二步**

分类，按照最小距离聚类（若$D_j=min(||x-z_i||),i=1,2,\dots,N_c,则x\in S_j$）

**第三步**

初始合并，若有任何一个类$S_j$,其样本数$N_j<\theta_N$，则舍去$S_j$,令$N_c=N_c-1$,将原样本分配至其他的类中

**第四步**

修正各聚类中心：$Z_j=\frac{1}{N_j}\sum\limits_{X\in S_j}X,j=1,2,\dots,N_c$

**第五步**

计算类内的平均距离：$D_j=\frac{1}{N_j}\sum\limits_{x\in S_j}||x-z_j||,j=1,2,\dots,N_c$

**第六步**

计算全体样本的平均距离：$D=\frac{1}{N}\sum\limits_{j=1}^{N_c} N_jD_j$

**第七步**

- 如果已经迭代$I$次，则不再合并分裂，转到第十一步处理，并设置$\theta_C=0$防止合并发生
- 如果$N_c\le\frac{K}{2}$(类数远少于期望值)，则转向第八步，分裂
- 如果迭代的次数为偶数，或者$N_c\ge 2K$，则转到第十一步，进行合并处理，否则转到第八步进行分裂

**第八步**

计算类内标准差向量。对于每个聚类$j$，求其标准差向量$\sigma_j=(\sigma_{j1},\sigma_{j2}\dots\sigma_{jn})^{'}$
$$
\sigma_{ji}=\sqrt{\frac{1}{N_j}\sum\limits_{x_k\in S_j}(x_{ki}-z_{ji})^2}
$$

- $\sigma_{ji}$是第$j$个聚类第$i$个分量的标准差
- $x_{ki}$是第$j$类中的第$k$个样本的第$i$个分量
- $z_{ji}$是均值向量$z_j$的第$i$个分量
- n是样本特征维数
- $j=1,2,\dots,N_c$是聚类数
- $i=1,2,\dots,n$是维数

**第九步**

计算每个类的标准差向量的最大分量：
$$
\sigma_{jmax},j=1,2,\dots,N_c
$$
**第十步**

在最大分量集$\sigma_{jmax},j=1,2,\dots,N_c$中，若有$\sigma_{jmax}>\theta_s$,则说明$S_j$类样本在对应方向上的标准差大于允许的值。如果又满足以下两个条件之一：

- $D_j>D$和$N_j>2(\theta_N+1)$，即类内的平均距离大于总体平均距离，并且$S_j$类中的样本数很大
- $N_c\le K/2$，即聚类数小于或者等于希望数目的一半，则将$Z_j$分裂成两个新的聚类中心$Z_j^+,Z_j^-$,并且令$N_c=N_C+1$，其中：

$$
Z_j^+:Z_j中对应\sigma_{jmax}的分量加上k\sigma_{jmax}\\
Z_j^-:Z_j中对应\sigma_{jmax}的分量减去k\sigma_{jmax}\\
0<k\le1,为分裂系数
$$

如果本步完成了分裂运算，迭代次数加1，跳回第二步，否则继续进行下一步

**第十一步**

计算类间聚类中心距离，$i$类与 $j$类的类间距离为：

$D_{ij}=||z_i-z_j||,i=1,2,\dots,N_c-1\ \ j=i+1,i+2,\dots,N_c$

**第十二步**

比较$D_{ij}$与$\theta_c$ 并将小于$\theta_c$的按上升次序排列如下（该队列的最大个数是控制合并对数的参数L)
$$
\{D_{i_1j_1},D_{i_2j_2},\dots,D_{i_Lj_L}\}
$$
式中，$D_{i_1j_1}<D_{i_2j_2}<\dots<D_{i_Lj_L}$

**第十三步**

从类间距离最小的两类开始执行合并过程，此时需将$z_{kl}$和$z_{il}$合并，同时执行$N_c=N_c-1$，新中心的计算公式如下：
$$
z_l^*=\frac{1}{N_{il}+N_{jl}}(N_{il}z_{il}+N_{jl}z_{jl})\ \ l=1,2,\dots.L
$$
每合并一对，$N_c$减1

**第十四步**

- 如果是最后一次迭代则终止
- 否则可根据需要转到第一步或者第二步，同时迭代次数加一



#### 优点

- 聚类中心个数可调
- 初始聚类中心位置对结果影响较小



#### 缺点

- 结果受模式样本几何性质影响
- 结果受样本顺序影响
- 算法复杂



### 4、ISODATA与k—均值算法的比较

|                                  | K—均值算法 | ISODATA算法 |
| -------------------------------- | ---------- | ----------- |
| 聚类中心通过样本均值迭代运算决定 | 是         | 是          |
| 聚类中心数可变                   | 否         | 是          |
| 结果受初始聚类中心影响           | 是         | 否          |
| 算法复杂度                       | 简单       | 复杂        |
| 结果受模式样本几何性质影响       | 是         | 是          |
| 结果受样本顺序影响               | 是         | 是          |





## 六、基于密度的聚类算法



### 1、简介



#### 基本思想

- 区域内点的密度大于每个阈值时，把它加到临近的聚类中
- 在一个给定半径$\varepsilon$的邻域中，至少要包含最小数目个对象



#### 优点

- 可以发现任意形状的聚类
- 对噪声不敏感



#### 代表算法

- DBSCAN
- OPTICS
- DENCLUE



### 2、DSBSCAN



#### 密度

-  数据集中特定点的密度通过该点Eps半径之内的点计数(包括本身)来估计



#### 点的类型

- 核心点：在半径Eps内含有超过MinPts数目的点，则该点为核心点
- 边界点:在半径Eps内点的数量小于MinPts，但是在核心点的邻域
- 噪声或者背景点：任何不是核心点或边界点的点

**Minpts：**点类型阈值

**Eps:**半径

![1571386541662](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571386541662.png)

#### 名词解释

- **Eps邻域**：给定对象半径Eps内的邻域称为该对象的Eps邻域，我们用$N_{Eps}(p)$表示点p的$Eps$半径内点的集合，即：

$$
N_{Eps}(p)=\{q|q在数据集D中，distance(p,q)\le Eps\}
$$

- **核心对象**：如果对象的Eps邻域至少包含最小数目的MinPts对象，则称该对象为核心对象
- **边界点**：边界点不是核心点，但落在某个核心点的邻域内
- **噪音点：**既不是核心点，也不是边界点的任何点



#### 算法概念

- **直接密度可达：**给定一个对象集合D，如果p在q的Eps邻域内，而q是一个核心对象，则称对象p 从对象q出发时是直接密度可达的(directly density-reachable)。
- **密度可达：**如果存在一个对象链$p_1,p_2,\dots,p_n,p_1=q,p_n=p$，对于 $p_i\in D(1\le i\le n)$，$p_{i+1}$是从$p_i$ 关于Eps和MinPts直接密度可达的，则对象p是从对象q关于Eps和MinPts密度可达的(density-reachable)。q是核心对象。
- **密度相连：**如果存在对象$O\in D$,使对象p和q都是从O关于Eps和MinPts密度可达的，那么对象p到q是关于Eps和MinPts密度相连的(density-connected)



#### 算法描述

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\1571836406513.png" alt="1571836406513" style="zoom:80%;" />



#### 优点

- 基于密度定义，相对抗噪声，能处理任意形状和大小的簇



#### 缺点

- 当簇的密度大小太大时，会有麻烦
- 对于高维问题，密度定义是比较麻烦的问题
- 参数的确定需要尝试或者先验知识



## 六、聚类结果评价



### 指标

- **聚类中心之间的距离**
  - 距离值大，通常可以分为不同类
- **聚类域中的样本数目**
  - 样本数目少且聚类中心距离远，可考虑是否为噪声
- **聚类域内样本的距离方差**
  - 方差过大的样本可考虑是否属于这一类

