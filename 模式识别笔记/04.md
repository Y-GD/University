# 第四章	基于统计决策的概率分类法



## 一、研究对象及相关概率



### 1、两类研究对象



为什么要将模式识别的研究对象分类？

- 分类后可以总结研究对象的特点，从而选择合适的算法



#### 确定性事件

- 定义

  事物间(即特征与分类间)有确定的因果关系

- 特点

  特征可以明确确定分类

- 分类方法

  线性判别函数



#### 随机事件

- 定义

  事物间(即特征与分类间)没有确定的因果关系

- 特点

  特征具有统计特性，是随机变量。同一个特征值可能是不同的分类

- 分类方法

  统计决策理论



#### 对比表

|          | **确定性事件**                                               | **随机事件**                                                 |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 定义     | 特征与分类间有确定的因果关系                                 | 即特征与分类间没有确定的因果关系                             |
| 特点     | 特征可以明确确定分类                                         | 特征不能明确确定分类（是随机变量）                           |
| 例子     | 根据特征（三条直线边的闭合连线和一个直角）可以确定这是一个直角三角形 | 根据特征（身高1.70米），不能确定该同学是男生还是女生，男生的概率大些。 |
| 分类算法 | 线性判别函数（第3章）                                        | 统计决策理论（第4章）                                        |



### 2、相关概率



#### 概率的定义



**名词解释**

- 基本空间($\Omega$)

  所有可能的实验结果或基本事件的全体构成

- 随机事件(A)

  某次实验获得的一个数据

- 概率的定义：

  p(A)为定义在所有随机事件组成的集合上的实函数，若P(A)满足：

  1. 对于任一事件A有，$0\le P(A)\le1$

  2. $p(\Omega)=1,\Omega-$事件的全体

  3. 对于两两互斥的事件$A_1,A_2,\dots$，有：

     $P(A_1+A_2+\dots)=p(A_1)+P(A_2)+\cdots$
  
   则称函数$P(A)$为事件A的概率



#### 概率的性质与条件概率



**概率的性质**

- 不可能事件$V$的概率为零，即$P(V)=0$
- $p(\bar{A})=1-P(A)$
- $P(A\cup B)=p(A)+p(B)-p(AB)$



**条件概率的定义**

- 设$A、B$是两个随机事件，且$P(B)>0$，则称：

  $P(A|B)=\frac{p(AB)}{p(B)}$

  为事件B发生的条件下事件A发生的条件概率



#### 条件概率的三个公式



**1、概率乘法公式**

如果$P(B)>0$，则联合概率

$P(AB)=P(B)P(A|B)=p(A)P(B|A)=p(BA)$



**2、全概率公式**

设事件$A_1,A_2,\dots,A_n$，两两互斥，且$\sum\limits_{i=1}^{n}A_i=\Omega,P(A_i)>0,i=1,2\dots,n$，则对任一事件B有：

$P(B)=\sum\limits_{i=1}^nP(A_i)P(B|A_i)$



**3、贝叶斯公式**

在全概率公式条件下，若$P(B)>0$，则将1、2式代入条件概率的定义式中：
$$
P(A_i|B)=\frac{P(A_i)P(B|A_i)}{\sum\limits_{i=1}^{n}P(A_i)P(B|A_i)}
$$



#### 模式识别中的三个概率

设随机样本向量$X$，相关的三个概率：

- 先验概率$P(w_i)$

  根据以前的知识和经验得出$w_i$类样本出现的概率

- 后验概率$P(w_i|X)$

  根据一批实验样本$X$统计出的$w_i$类出现的概率

- 条件概率$P(X|w_i)$

  已知属于$w_i$类的样本$X$，发生某种事件的概率

今后的分类中常用到类概率密度函数$P(X|w_i)$：$w_i$类的条件概率密度函数，通常也称为$w_i$的似然函数



**条件概率的比较**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124105716794.png" alt="image-20191124105716794" style="zoom:50%;" />



**三个概率的关系**

将$A_i=w_i,B=X$带入贝叶斯公式$P(A_i|B)=\frac{p(A_i)p(B|A_i)}{\sum\limits_{i=1}^{n}P(A_i)P(B|A_i)}$得到：
$$
P(w_i|X)=\frac{p(X|w_i)p(w_i)}{p(X)}=\frac{P(X|w_i)P(w_i)}{\sum\limits_{i=1}^MP(X|w_i)P(w_i)}
$$
$M：$类别数



## 二、贝叶斯决策



### 1、最小错误率贝叶斯决策



#### 基本形式

- 解决的问题：

  最小错误率贝叶斯决策用于解决分类的问题。即给定特征$X$，判断它所属类别$w$的问题

- 决策规则

  若$p(w_i|X)=\max\{P(w_j|X),j=1,2\dots,M，则X\in w_i类\}$

- 说明
  1. 上述规则为最小错误率贝叶斯决策的基本形式
  2. 上述规则使用后验概率来决定分类



#### 等价形式



**等价形式1**

由于$P(w_i|X)=\frac{p(X|w_i)P(w_i)}{P(X)}$，而分母$P(X)$与分类无关，故$P(w_i|X)$取最大值，等价于$P(X|w_i)P(w_i)$取最大值

- 决策规则

  若$P(X|w_i)P(w_i)=\max\{P(X|w_j)P(w_j),j=1,2,\dots,M，则X\in w_i类\}$

- 说明

  1. 上述规则使用先验概率和条件概率来决定分类
  2. 先验概率和条件概率可从从前的统计资料中轻易获得，故上述规则更实用

**等价形式2**

对于两类问题：

- 若$P(X|w_1)p(w_1)>p(X|w_2)p(w_2)$，则$X\in w_1$
- 若$P(X|w_1)p(w_1)<p(X|w_2)p(w_2)$，则$X\in w_2$

可以改写为：

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124112601325.png" alt="image-20191124112601325"  />

统计学中称$l_{12}(X)$为似然比，$P(w_2)/P(w_1)$为似然比阈值

说明

1. 上述规则用于处理二分类问题
2. 上述规则使用似然比来决定分类



**等价形式3**

对$l_{12}(X)$取自然对数，有：

![image-20191124112925992](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124112925992.png)

说明

1. 上述规则用于处理二分类问题
2. 上述规则使用似然比对数形式来决定分类





### 2、最小风险贝叶斯决策



#### 风险的概念

- **最小错误率贝叶斯决策的问题**

  1. 没有考虑不同类错误率的重要性
  2. 例如，癌细胞漏判比正常细胞错判危害大；火警漏报比误报严重

- **解决办法**

  1. 将错判风险问题加入到最小错误率贝叶斯决策中
  2. 提出最小风险贝叶斯决策

- **最小风险贝叶斯决策的基本思想**

  以各种错误分类所造成的**平均风险**最小为规则，进行分类决策



#### 决策规则



**1、条件平均风险计算公式**

对$M$类问题，如果观察样本$X$被判定属于$w_i$类，则条件平均风险$r_i(X)$指将$X$判为属于$w_i$类所造成的平均损失：
$$
r_i(x)=\sum\limits_{j=1}^{M}L_{ij}(X)P(w_j|X)
$$
式中：

- $i：$分类判决后指定的判决号
- $j:$样本实际属于的类别号
- $L_{ij}:$将自然属性是$w_j$类的样本决策为$w_i$类时的是非代价，即损失函数

$$
L_{ij(X)}=
\begin{cases}
0或负值\ \ &i=j\\
正值&i\ne j
\end{cases}
$$



**2、基于条件平均风险的决策规则**

对于每一个$X$有$M$中可能的类别划分，$X$被判决为每一类的条件平均风险分别为$r_1(X),r_2(X),\dots,r_M(X)$，决策规则为：

- 若$r_k(X)=\min\{r_i(X)，i=1，\dots,M\}$，则$X\in w_k$
- 每个$X$都按条件平均风险最小决策，则总的条件平均风险也最小。总的条件平均风险成为**平均风险**



**3、多类情况的贝叶斯化简**
$$
\begin{align}
r_i(X)&=\sum\limits_{j=1}^{M}L_{ij}P(w_j|X)\\
&=\sum\limits_{j=1}^{M}L_{ij}\frac{P(X|w_j)P(w_j)}{P(X)}\\
&=\frac1{P(X)}\sum\limits_{j=1}^{M}L_{ij}P(X|w_j)P(w_j)
\end{align}
$$
因为$P(X)$对所有类别一样，不提供分类信息，所以可以化简为：

$r_i(X)=\sum\limits_{j=1}^{M}L_{ij}P(X|w_j)P(w_j)，i=1,2,\dots,M$

**决策规则：**

若$r_k(X)<r_i(X)，i=1，2\dots,M；i\ne k，则X\in w_k$

 

**两类情况的贝叶斯化简**

- 当$X$被判定为$w_1$类时：$r_1(X)=L_{11}P(X|w_1)P(w_1)+L_{12}p(X|w_2)P(w_2)$
- 当$X$被判定为$w_2$类时：$r_2(X)=L_{21}P(X|w_1)P(w_1)+L_{22}p(X|w_2)P(w_2)$

**决策规则**：
$$
若r_1(X)<r_2(X),则X\in w_1\\
若r_1(X)>r_2(X),则X\in w_2
$$
**化简**：

![image-20191124181649093](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124181649093.png)

- 令$l_{12}(X)=\frac{P(X|w_1)}{P(X|w_2)}$，称为似然比
- 令$\theta_{12}=\frac{(L_{12}-L_{22})P(w_2)}{(L_{21}-L_{11})P(w_1)}$，称为阈值

**判决步骤**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124182105688.png" alt="image-20191124182105688" style="zoom:67%;" />



#### (0-1)损失最小风险贝叶斯决策

损失函数为特殊情况时：

- $L_{ii}=0$
- $L_{ij}=1，i\ne j$

**多类情况**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124183440249.png" alt="image-20191124183440249" style="zoom:80%;" />

- 判别函数的等价形式：$d_i(X)=p(X|w_i)P(w_i)，i=1,2,\cdots,M$

- 决策规则的等价形式：

  若$d_k(X)>d_i(X)，i=1,2,\cdots,M，i\ne k$，则$X\in w_k$

- 即:**(0-1)损失最小风险贝叶斯决策就是最小错误率贝叶斯决策**



**两类情况**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124184040956.png" alt="image-20191124184040956" style="zoom:80%;" />

令$l_{12}(X)=\frac{P(X|w_1)}{P(X|w_2)}$，$\theta_{12}=\frac{P(w_2)}{P(w_1)}$

决策规则为：

- 若$l_{12}(X)>\theta_{12}，则X\in w_1$
- 若$l_{12}(X)<\theta_{12}，则X\in w_2$



### 3、正态分布模式的贝叶斯决策



#### 单变量（一维）的正态分布

概率密度函数定义为：
$$
p(X)=\frac1{\sqrt{2\pi}\sigma}e^{-\frac{(x-u)^2}{2\sigma^2}}
$$
其中，$u$为均值，$\sigma$为方差



**一维正态分布的性质**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124185106644.png" alt="image-20191124185106644" style="zoom:50%;" />

1. 曲线在 x 轴的上方，与x轴不相交。
2. 曲线关于直线 x =μ对称。
3. 当 x =μ时，曲线位于最高点
4. 当x＜μ时，曲线上升；当x＞μ时，曲线下降.并且当曲线向左、右两边无限延伸时，以x轴为渐近线，向它无限靠近。
5. μ一定时，曲线的形状由σ确定。σ越大，曲线越“矮胖”，表示总体的分布越分散；σ越小。曲线越“瘦高”。表示总体的分布越集中。 
6. 正态分布的概率密度曲线可由均值和方差来确定，常简记为：$p(x)～N(u,\sigma^2)$



**3$\sigma$规则**

绝大部分的样本都落在了均值$u$附近的$3\sigma$的范围内

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124185342370.png" alt="image-20191124185342370" style="zoom:50%;" />

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124185505182.png" alt="image-20191124185505182" style="zoom:50%;" />



#### 多变量(n维)正态随机变量

![image-20191124185732964](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124185732964.png)



**n维正态分布的性质**

多维正态密度函数完全由它的均值$ M $和协方差矩阵$C$所确定，简记为：$p(X)～N( M , C )$。其他性质与一维类似



**n维正态分布的例子**

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124190049850.png" alt="image-20191124190049850" style="zoom:50%;" />

（1）等高线（等密度线）投影到$x_1ox_2$面上为椭圆。
（2）从原点$O$到点$M$的向量为均值$M$。
（3）椭圆的位置：由均值向量$M$决定；
（4）椭圆的形状：由协方差矩阵$C$决定。



#### 基础知识

**二次型**

设一向量$X=[x_1,x_2,\dots,x_n]^T$，$A=\begin{bmatrix}a_{11}&\cdots &a_{1n}\\ \vdots&&\vdots\\a_{n1}&\cdots& a_{nn}\end{bmatrix}$，则$X^TAX$称为二次型

- 二次型是一个二次齐次多项式$X^TAX=\sum\limits_{i,j=1}^na_{ij}x_ix_j$
- 二次型中的矩阵是一个对称矩阵，即$a_{ij}=a_{ji}$



**正定二次型**

对于$\forall X\ne0$(即$X$分量不全为0),总有$X^TAX>0$，则称此二次型是正定的，而其对应的矩阵称为对称矩阵



#### 多类问题



**1、判别函数**

若$P(X|w_i)P(w_i)=\max\{P(X|w_j)P(w_j)\}，j=1,2,\dots,M，则X\in w_i类$



**2、求$p(X|w_i)$**

![image-20191124192206454](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124192206454.png)



**3、判别函数化简**

![image-20191124192401207](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124192401207.png)



**4、正态分布的最小错误率贝叶斯决策规则总结**

- 判决函数

  $d_i(X)=ln\ p(w_i)-\frac12ln\ |C_i|-\frac12\{(X-M_i)^TC_i^{-1}(X-M_i)\}$

- 判决规则

  若$d_j(X)>d_i(X)，i=1，2，\dots，M,i\ne j$，则$X\in w_j$

- 核心思想

  把最小错误率贝叶斯决策中的条件概率$p(X|w_i)$用正态分布的形式写出来，然后再化简

- 优点

  只要知道均值向量和协方差矩阵，就能进行判决



#### 两类问题

$C_1\ne C_2$：

![image-20191124211705341](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124211705341.png)



$C_1=C_2=C$：

![image-20191124211805080](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124211805080.png)



$C_1=C_2=I，且P(w_1)=P(w_2)=\frac12$

![image-20191124211941201](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124211941201.png)





## 三、贝叶斯分类器的错误率



### 1、错误率的概念

错误率是指将应属于某一类的模式错分到其他类中的概率



#### 使用错误率的原因

- 任何决策规则都有错误率，因此必须研究错误率
- 错误率的大小可以衡量分类器的优劣
- 是模式识别的重要参数



#### 错误率的定义：

平均错误率：
$$
P(e)=\int_{-\infty}^{\infty}P(e|X)P(X)dX
$$


#### 错误率的计算方法

- 按理论公式计算
- 计算错误率上界
- 实验估计



### 2、错误率分析



#### 两类问题

![image-20191124213211097](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124213211097.png)

**错误率图示：**

![image-20191124213346203](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124213346203.png)



#### 多类问题

![image-20191124213627694](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124213627694.png)



### 3、正态分布贝叶斯决策的错误率计算



#### 正态分布的对数似然比

![image-20191124214157856](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124214157856.png)



#### 对数似然比的概率分布

![image-20191124214815673](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191124214815673.png)



#### 正态分布最小错误率贝叶斯决策的错误率

![image-20191125192640360](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125192640360.png)

所以错误率为：

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125192911727.png" alt="image-20191125192911727" style="zoom:80%;" />
$$
P(e)=\int_{\frac{r_{12}}{2}}^{\infty} \frac{1}{\sqrt{2\pi}}exp(-\frac{y^2}{2})\ dy
$$

- 性质：错误率随着两类间距离的增加而单调递减
- 物理意义：两类间的差距越大，错误率越小



### 4、错误率的估计

- 由于理论计算错误率往往太过复杂，因此往往采用错误率的估计
- 方法：通过实验的方法，利用样本求错误率的估计值
- 场景：
  - 已设计好分类器时错误率的估计
  - 未设计好分类器时错误率的估计



#### 已设计好分类器时错误率估计



**1、先验概率未知**

- 采用随机抽样
- **基本做法：**设$\varepsilon$为真实的错误率，则随机抽取$N$个样本，假设分类器错分样本数为$k$，则可以用公式$\varepsilon^{'}=\frac{k}{N}$来估计$\varepsilon$



**2、先验概率已知**

- 采用选择性抽样
- **基本做法：**设$\varepsilon$为真实的错误率，先验概率为$p(w_1)$;则根据分类器的结果，从$w_1$中抽取$N_1=P(w_1)N$个样本，从$w_2$中抽取$N_2=P(w_2)N$个样本，用类似的方法可以求得错误率$\varepsilon$的最大似然估计值为：$\varepsilon^{'}=\sum\limits_{i=1}^2p(w_i)\frac{k_i}{N_i}$
- 先验概率已知时，两类可以分别估计，再用先验概率取平均值



#### 未设计好分类器时错误率的估计

- **解决的问题**

  1. 分类器未设计好
  2. 同一批样本既用来训练也用来估计错误

- **基本思路**

  对样本进行划分，决定那些用于设计分类器，哪些用于检验分类器的错误率

- **常用的划分方法**

  1. 部分样本($N$个)用于设计分类器；同样$N$个样本用于测试：错误率小些，是下限
  2. 部分样本($N$个)用于设计分类器；全部样本用于测试：错误率大些，是上限
  3. 样本划分法：一部分样本用于设计分类器；另外一部分用于测试；适合于样本数据很大的情况。
  4. 留一法：将$N$个样本每次留一个测试，其他的训练，重复$N$次，每次留不同的样本，根据错误数来估计错误率，适合于小样本



## 四、聂曼-皮尔逊决策



### 1、基本思想

![image-20191125213514200](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125213514200.png)

**基本思想**

在$p_2(e)$等于常数的条件下，使得$p_1(e)$为最小，依次来确定阈值$t$

![image-20191125213801246](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125213801246.png)



### 2、判别式的推导

#### 推导决策条件



**问题**

在$P_2(e)$等于常数的情况下，求$P_1(e)$极小值的条件极值问题



**1、构造辅助函数**

令$Q=P_1(e)+uP_2(e)$

- $u$为待定常数
- $P_2(e)$为常数
- $P_1(e)=\int_{R_2}\ P(X|w_1) dX$
- $P_2(e)=\int_{R_1}\ P(X|w_2) dX$

求$P_1(e)$最小，即求$Q$最小



**2、化简**
$$
\begin{align}
Q&=\int_{R_2}\ P(X|w_1) dX+u\int_{R_1}\ P(X|w_2) dX\\
&=(1-\int_{R_1}P(X|w_1)dX)+u\int_{R_1}\ P(X|w_2) dX\\
&=1-\int_{R_1}[P(X|w_1)-uP(X|w_2)]\ dX\\\\
同理&：\\
Q&=\int_{R_2}P(X|w_1)dX+u(1-\int_{R_2}P(X|w_2)dX)\\
&=u-\int_{R_2}[uP(X|w_2)-P(X|w_1)]dX

\end{align}
$$



**3、极值条件**

- 要使$Q$最小，应该使积分项为正值，即在$R_1$区域内，应保证$P(X|w_1)>uP(X|w_2)$，即$\frac{P(X|w_1)}{P(X|w_2)}>u\Rightarrow X\in w_1$
- 同理，在$R_2$区域内，应保证$uP(X|w_2)>p(X|w_1)$，即$\frac{P(X|w_1)}{P(X|w_2)}<u\Rightarrow X\in w_2$



**4、决策规则**

![image-20191125220051474](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125220051474.png)



#### 确定似然比阈值u

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125220350525.png" alt="image-20191125220350525" style="zoom:50%;" />

求解$u$值从常数$P_2(e)$入手，这时由$P_2(e)=\int_{R_1}P(X|w_2)dX$有：
$$
P_2(e)=\int_{-\infty}^{t(u)}P(X|w_2)dX
$$
由于：

1. $P_2(e)$已知
2. $P(X|w_2)$服从正态分布

所以可以通过查标准正态分布表求$u$的值



#### 查表说明

<img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125220836023.png" alt="image-20191125220836023" style="zoom:67%;" />
$$
\Phi(\lambda)=\int_{-\infty}^{\lambda}\varphi(x)dx
$$

- 表中为$\lambda\ge0$时，$\Phi(\lambda)$的值
- 纵向值：$\lambda$的整数部分和小数点后一位
- 横向值：$\lambda$的小数点后第二位

![image-20191125221609059](C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125221609059.png)



#### 正态分布概率计算

- 左边阴影部分的面积表示为概率。即分布函数：

  $\Phi(\lambda)=\int_{-\infty}^{\lambda}\varphi(x)dx$

  <img src="C:\Users\杨士伟\AppData\Roaming\Typora\typora-user-images\image-20191125221837640.png" alt="image-20191125221837640" style="zoom:50%;" />

- 当$\lambda<0$时，$\Phi(\lambda)=1-\Phi(-\lambda)$

- $\phi(\lambda)=\int_{-\infty}^{\infty}\varphi(x)dx=1$

- 在任意区间$(\lambda_1,\lambda_2)$内取值的概率：

  $P(\lambda_1<\lambda<\lambda_2)=\int_{\lambda_1}^{\lambda_2}\varphi(x)dx=\Phi(\lambda_2)-\Phi(\lambda_1)$





### 3、聂曼-皮尔逊决策与贝叶斯决策的比较表

|                      | **最小错误贝叶斯决策**      | **最小风险贝叶斯决策**                                | 聂曼-皮尔逊决策                  |
| -------------------- | --------------------------- | ----------------------------------------------------- | -------------------------------- |
| 基本思想             | 使总错误率最小              | 使风险（错误引起的损失）最小                          | 限制一个错误概率，追求另一个最小 |
| 判决阈值(即判决界面) | $\frac{P(w_2)}{P(w_1)}$     | $\frac{(L_{12}-L_{22})P(w_2)}{(L_{21}-L_{11})P(w_1)}$ | *μ*                              |
| 判别式               | $\frac{P(X|w_1)}{P(X|w_2)}$ | $\frac{P(X|w_1)}{P(X|w_2)}$                           | $\frac{P(X|w_1)}{P(X|w_2)}$      |



